import os
import json
import time
import uuid
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional, List
from collections import defaultdict
import boto3
from botocore.exceptions import ClientError


class LogSink:
    """
    ë¡œê·¸ ìµœì¢… ì²˜ë¦¬ í´ë˜ìŠ¤

    ì±…ì„:
    - ë¡œê·¸ ì¶œë ¥ ë°©ì‹ ê²°ì • (ë¡œì»¬/S3/Kinesis)
    - MSK S3 Sink Connectorì™€ ë™ì¼í•œ í´ë” êµ¬ì¡°/íŒŒì¼ëª… ìƒì„±
    - MPS(Messages Per Second) ì œì–´
    """

    def __init__(self, config: dict):
        """
        Args:
            config: config.toml ì „ì²´ dict
        """
        self.config = config

        # Global ì„¤ì •
        global_config = config.get("global", {})
        self.mode = global_config.get("generation_mode", "batch")

        # MPS ì„¤ì •
        target_mps = global_config.get("target_mps", 0)
        if target_mps > 0:
            self.interval = 1.0 / target_mps
        else:
            self.interval = 0  # MPS ì œí•œ ì—†ìŒ

        # LogSink ì „ìš© ì„¤ì •
        sink_config = config.get("log_sink", {})

        # Kinesis ë°°ì¹˜ ì „ì†¡ ì„¤ì •
        self.batch_size = sink_config.get("batch_size", 500)
        self.batch_timeout_ms = sink_config.get("batch_timeout_ms", 1000)

        self.sink_type = sink_config.get("sink_type", "local")  # local, s3, kinesis

        # ë¡œì»¬ ì €ì¥ ì„¤ì •
        self.output_dir = sink_config.get("output_dir", "./output")
        self.topic = sink_config.get("topic", "user-logs")
        self.partition = sink_config.get("partition", 0)

        # S3 ì„¤ì •
        self.s3_bucket = sink_config.get("s3_bucket", "sesac-l1")
        self.s3_prefix = sink_config.get("s3_prefix", "raw-userlog")

        # Kinesis ì„¤ì •
        self.kinesis_stream_name = sink_config.get("kinesis_stream_name", "user-logs-stream")
        self.kinesis_region = sink_config.get("kinesis_region", "ap-northeast-2")
        self.aws_profile = sink_config.get("aws_profile", None)  # AWS CLI Profile

        # Kinesis ì¬ì‹œë„ ì„¤ì •
        self.max_retries = sink_config.get("max_retries", 3)
        self.initial_backoff_ms = sink_config.get("initial_backoff_ms", 100)
        self.max_backoff_ms = sink_config.get("max_backoff_ms", 5000)

        # Kinesis client ì´ˆê¸°í™” (kinesis ëª¨ë“œì¼ ë•Œë§Œ)
        self.kinesis_client = None
        if self.sink_type == "kinesis":
            # AWS Profileì´ ì§€ì •ëœ ê²½ìš° session ì‚¬ìš©
            if self.aws_profile:
                session = boto3.Session(profile_name=self.aws_profile)
                self.kinesis_client = session.client('kinesis', region_name=self.kinesis_region)
            else:
                # Profile ë¯¸ì§€ì • ì‹œ ê¸°ë³¸ ì¸ì¦ ë°©ë²• ì‚¬ìš© (í™˜ê²½ ë³€ìˆ˜, IAM Role ë“±)
                self.kinesis_client = boto3.client('kinesis', region_name=self.kinesis_region)

        # ì‹œê°„ë³„ ì˜¤í”„ì…‹ ì¹´ìš´í„° (íŒŒì¼ëª…ìš©)
        self.hourly_offsets: Dict[str, int] = defaultdict(int)

        # í˜„ì¬ ì‹œê°„ëŒ€ ë²„í¼ì™€ ë‹¤ìŒ ì‹œê°„ëŒ€ ë²„í¼ (ë‘ ê°œì˜ ë²„í¼ë¡œ ê´€ë¦¬)
        self.current_hour_key: Optional[str] = None
        self.current_hour_buffer: List[Dict[str, Any]] = []

        self.next_hour_key: Optional[str] = None
        self.next_hour_buffer: List[Dict[str, Any]] = []

        # Kinesis ë°°ì¹˜ ì „ì†¡ìš© ë²„í¼ (streaming-batch ëª¨ë“œ ì „ìš©)
        self.kinesis_batch_buffer: List[Dict[str, Any]] = []
        self.last_batch_send_time = time.time()

        print(f"âœ… LogSink ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   Mode: {self.mode}")
        print(f"   Sink Type: {self.sink_type}")
        print(f"   Target MPS: {target_mps if target_mps > 0 else 'ì œí•œ ì—†ìŒ'}")
        if self.sink_type == "local":
            print(f"   Output Dir: {self.output_dir}")
            print(f"   Topic: {self.topic}")
        elif self.sink_type == "s3":
            print(f"   S3 Bucket: {self.s3_bucket}")
            print(f"   S3 Prefix: {self.s3_prefix}")
        elif self.sink_type == "kinesis":
            print(f"   Kinesis Stream: {self.kinesis_stream_name}")
            print(f"   Kinesis Region: {self.kinesis_region}")
            if self.mode == "streaming-batch":
                print(f"   Batch Size: {self.batch_size}")
                print(f"   Batch Timeout: {self.batch_timeout_ms}ms")


    def write(self, log_event: Dict[str, Any]) -> None:
        """
        ë¡œê·¸ ì“°ê¸° (ëª¨ë“œì— ë”°ë¼ ë¶„ê¸°)

        Args:
            log_event: ë¡œê·¸ ë”•ì…”ë„ˆë¦¬
        """
        if log_event is None:
            return

        if self.mode == "streaming-single":
            self.streaming_single_write(log_event)
        elif self.mode == "streaming-batch":
            self.streaming_batch_write(log_event)
        else:  # batch
            self.batch_write(log_event)


    def streaming_single_write(self, log_event: Dict[str, Any]) -> None:
        """
        Streaming Single ëª¨ë“œ: Kinesisë¡œ ì¦‰ì‹œ ë‹¨ì¼ ì „ì†¡ (put_record)

        ì§€ì›: Kinesisë§Œ
        ë¯¸ì§€ì›: Local, S3

        Args:
            log_event: ë¡œê·¸ ë”•ì…”ë„ˆë¦¬
        """
        if self.sink_type == "kinesis":
            self._write_to_kinesis_single(log_event)
        else:
            print(f"âŒ Streaming ëª¨ë“œëŠ” Kinesisë§Œ ì§€ì›í•©ë‹ˆë‹¤. (í˜„ì¬ sink_type: {self.sink_type})")
            return

        # MPS ì œì–´
        if self.interval > 0:
            time.sleep(self.interval)

    def streaming_batch_write(self, log_event: Dict[str, Any]) -> None:
        """
        Streaming Batch ëª¨ë“œ: Kinesisë¡œ ë°°ì¹˜ ì „ì†¡ (put_records)

        ì§€ì›: Kinesisë§Œ
        ë¯¸ì§€ì›: Local, S3

        Args:
            log_event: ë¡œê·¸ ë”•ì…”ë„ˆë¦¬
        """
        if self.sink_type != "kinesis":
            print(f"âŒ Streaming ëª¨ë“œëŠ” Kinesisë§Œ ì§€ì›í•©ë‹ˆë‹¤. (í˜„ì¬ sink_type: {self.sink_type})")
            return

        # ë²„í¼ì— ì¶”ê°€
        self.kinesis_batch_buffer.append(log_event)

        # ë°°ì¹˜ ì „ì†¡ ì¡°ê±´ ì²´í¬
        current_time = time.time()
        buffer_full = len(self.kinesis_batch_buffer) >= self.batch_size
        timeout_reached = (current_time - self.last_batch_send_time) * 1000 >= self.batch_timeout_ms

        if buffer_full or timeout_reached:
            self._flush_kinesis_batch()

        # MPS ì œì–´
        if self.interval > 0:
            time.sleep(self.interval)


    def batch_write(self, log_event: Dict[str, Any]) -> None:
        """
        Batch ëª¨ë“œ: ë²„í¼ì— ëª¨ì•„ì„œ íŒŒì¼ë¡œ ì €ì¥

        ì§€ì›: Local, S3
        ë¯¸ì§€ì›: Kinesis

        Args:
            log_event: ë¡œê·¸ ë”•ì…”ë„ˆë¦¬
        """
        if self.sink_type == "local":
            self._write_to_local(log_event)
        elif self.sink_type == "s3":
            self._write_to_s3(log_event)
        else:
            print(f"âŒ Batch ëª¨ë“œëŠ” Local/S3ë§Œ ì§€ì›í•©ë‹ˆë‹¤. (í˜„ì¬ sink_type: {self.sink_type})")
            return

        # MPS ì œì–´
        if self.interval > 0:
            time.sleep(self.interval)


    def _write_to_local(self, log_event: Dict[str, Any]) -> None:
        """
        ë¡œì»¬ íŒŒì¼ì— JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥

        í´ë” êµ¬ì¡°: {output_dir}/{topic}/year={YYYY}/month={MM}/day={DD}/hour={HH}/
        íŒŒì¼ëª…: {topic}-{offset(6ìë¦¬)}-{uuid}.json

        í˜„ì¬ ì‹œê°„ëŒ€ ë²„í¼ì™€ ë‹¤ìŒ ì‹œê°„ëŒ€ ë²„í¼ ë‘ ê°œë¡œ ê´€ë¦¬
        - í˜„ì¬ ì‹œê°„ëŒ€ ë¡œê·¸ â†’ í˜„ì¬ ë²„í¼ì— ì¶”ê°€
        - ë‹¤ìŒ ì‹œê°„ëŒ€ ë¡œê·¸ â†’ ë‹¤ìŒ ë²„í¼ì— ì¶”ê°€
        - ì‹œê°„ëŒ€ ë³€ê²½ ì‹œ â†’ í˜„ì¬ ë²„í¼ flush, ë‹¤ìŒ ë²„í¼ë¥¼ í˜„ì¬ ë²„í¼ë¡œ ìŠ¹ê²©
        """
        timestamp_str = log_event.get("timestamp", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))

        # ISO 8601 í˜•ì‹ ì§€ì› (2025-09-01T01:18:20.000Z)
        if "T" in timestamp_str:
            # ë°€ë¦¬ì´ˆ ì œê±° í›„ íŒŒì‹±
            timestamp_str_clean = timestamp_str.replace("Z", "").split(".")[0]
            timestamp = datetime.strptime(timestamp_str_clean, "%Y-%m-%dT%H:%M:%S")
        else:
            timestamp = datetime.strptime(timestamp_str, "%Y-%m-%d %H:%M:%S")

        year = timestamp.strftime("%Y")
        month = timestamp.strftime("%m")
        day = timestamp.strftime("%d")
        hour = timestamp.strftime("%H")

        hour_key = f"{year}-{month}-{day}-{hour}"

        # ì²« ë²ˆì§¸ ë¡œê·¸ì¸ ê²½ìš° ì´ˆê¸°í™”
        if self.current_hour_key is None:
            self.current_hour_key = hour_key
            self.current_hour_buffer.append(log_event)
            return

        # í˜„ì¬ ì‹œê°„ëŒ€ ë¡œê·¸ì¸ ê²½ìš°
        if hour_key == self.current_hour_key:
            self.current_hour_buffer.append(log_event)

        # ë‹¤ìŒ ì‹œê°„ëŒ€ ë¡œê·¸ì¸ ê²½ìš°
        elif self.next_hour_key is None or hour_key == self.next_hour_key:
            if self.next_hour_key is None:
                self.next_hour_key = hour_key
            self.next_hour_buffer.append(log_event)

        # ìƒˆë¡œìš´ ì‹œê°„ëŒ€ë¡œ ì „í™˜ (í˜„ì¬ â†’ ë‹¤ìŒ â†’ ìƒˆë¡œìš´)
        else:
            # 1. í˜„ì¬ ì‹œê°„ëŒ€ ë²„í¼ë¥¼ flush
            self._flush_buffer_to_json(self.current_hour_key, self.current_hour_buffer)

            # 2. ë‹¤ìŒ ì‹œê°„ëŒ€ ë²„í¼ë¥¼ í˜„ì¬ ì‹œê°„ëŒ€ë¡œ ìŠ¹ê²©
            self.current_hour_key = self.next_hour_key
            self.current_hour_buffer = self.next_hour_buffer

            # 3. ìƒˆë¡œìš´ ë‹¤ìŒ ì‹œê°„ëŒ€ ì„¤ì •
            self.next_hour_key = hour_key
            self.next_hour_buffer = [log_event]


    def _flush_buffer_to_json(self, hour_key: str, buffer: List[Dict[str, Any]]) -> None:
        """
        íŠ¹ì • ì‹œê°„ëŒ€ ë²„í¼ì— ìŒ“ì¸ ë¡œê·¸ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥

        Args:
            hour_key: "YYYY-MM-DD-HH" í˜•ì‹ì˜ ì‹œê°„ í‚¤
            buffer: ì €ì¥í•  ë¡œê·¸ ë¦¬ìŠ¤íŠ¸
        """
        if not buffer:
            return

        # ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_logs = sorted(buffer, key=lambda x: x.get("timestamp", ""))

        # ì²« ë²ˆì§¸ ë¡œê·¸ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ê²½ë¡œ ê²°ì •
        first_log = sorted_logs[0]
        timestamp_str = first_log.get("timestamp", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))

        # ISO 8601 í˜•ì‹ ì§€ì› (2025-09-01T01:18:20.000Z)
        if "T" in timestamp_str:
            # ë°€ë¦¬ì´ˆ ì œê±° í›„ íŒŒì‹±
            timestamp_str_clean = timestamp_str.replace("Z", "").split(".")[0]
            timestamp = datetime.strptime(timestamp_str_clean, "%Y-%m-%dT%H:%M:%S")
        else:
            timestamp = datetime.strptime(timestamp_str, "%Y-%m-%d %H:%M:%S")

        year = timestamp.strftime("%Y")
        month = timestamp.strftime("%m")
        day = timestamp.strftime("%d")
        hour = timestamp.strftime("%H")

        # í´ë” êµ¬ì¡° ìƒì„±
        dir_path = Path(self.output_dir) / self.topic / f"year={year}" / f"month={month}" / f"day={day}" / f"hour={hour}"
        dir_path.mkdir(parents=True, exist_ok=True)

        # íŒŒì¼ëª… ìƒì„±: {topic}-{offset(6ìë¦¬)}-{uuid}.json
        offset = self.hourly_offsets[hour_key]
        file_uuid = str(uuid.uuid4())[:6]  # ì§§ì€ UUID
        filename = f"{self.topic}-{offset:06d}-{file_uuid}.json"
        file_path = dir_path / filename

        # detailì—ì„œ null ê°’ ì œê±°
        def remove_nulls(detail: dict) -> dict:
            return {k: v for k, v in detail.items() if v is not None}

        # NDJSON (Newline Delimited JSON) í˜•ì‹ìœ¼ë¡œ ì €ì¥
        # Kinesisì—ì„œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ê° ë¡œê·¸ë¥¼ í•œ ì¤„ì”© ì €ì¥
        with open(file_path, 'w', encoding='utf-8') as f:
            for log in sorted_logs:
                log_entry = {
                    "timestamp": log["timestamp"],
                    "user_id": log["user_id"],
                    "event_category": log["event_category"],
                    "event_type": log["event_type"],
                    "detail": remove_nulls(log["detail"])
                }
                # ê° ë¡œê·¸ë¥¼ í•œ ì¤„ë¡œ ì‘ì„± (ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„)
                f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')

        print(f"ğŸ’¾ JSON ì €ì¥: {filename} ({len(sorted_logs)}ê°œ ë¡œê·¸)")

        # offset ì¦ê°€
        self.hourly_offsets[hour_key] += 1


    def _write_to_s3(self, log_event: Dict[str, Any]) -> None:
        """
        S3ì— ì €ì¥ (í–¥í›„ êµ¬í˜„)

        TODO: boto3ë¥¼ ì‚¬ìš©í•˜ì—¬ S3ì— ì—…ë¡œë“œ
        """
        # ì¼ë‹¨ ë¡œì»¬ì— ì €ì¥í•œ í›„ S3 ì—…ë¡œë“œí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬í˜„ ê°€ëŠ¥
        self._write_to_local(log_event)

        # TODO: S3 ì—…ë¡œë“œ ë¡œì§
        # import boto3
        # s3_client = boto3.client('s3')
        # s3_client.upload_file(local_file, bucket, key)


    def _write_to_kinesis_single(self, log_event: Dict[str, Any]) -> None:
        """
        Kinesis Data Streamsë¡œ ë‹¨ì¼ ì „ì†¡ (put_record)

        Args:
            log_event: ë¡œê·¸ ë”•ì…”ë„ˆë¦¬
        """
        if self.kinesis_client is None:
            print("âŒ Kinesis clientê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return

        try:
            # user_idë¥¼ partition keyë¡œ ì‚¬ìš© (ê°™ì€ ìœ ì €ì˜ ë¡œê·¸ëŠ” ê°™ì€ ìƒ¤ë“œë¡œ)
            partition_key = str(log_event.get("user_id", "default"))

            # JSONì„ ë°”ì´íŠ¸ë¡œ ë³€í™˜
            data = json.dumps(log_event, ensure_ascii=False).encode('utf-8')

            # Kinesisë¡œ ì „ì†¡
            response = self.kinesis_client.put_record(
                StreamName=self.kinesis_stream_name,
                Data=data,
                PartitionKey=partition_key
            )

            # ì„±ê³µ ë¡œê·¸ (ì„ íƒì )
            print(f"âœ… Kinesis ë‹¨ì¼ ì „ì†¡ ì„±ê³µ: ShardId={response['ShardId']}, SequenceNumber={response['SequenceNumber']}")

        except ClientError as e:
            print(f"âŒ Kinesis ì „ì†¡ ì‹¤íŒ¨: {e}")
        except Exception as e:
            print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")

    def _flush_kinesis_batch(self) -> None:
        """
        Kinesis ë°°ì¹˜ ë²„í¼ë¥¼ ë¹„ìš°ê³  put_recordsë¡œ ì „ì†¡
        """
        if not self.kinesis_batch_buffer:
            return

        if self.kinesis_client is None:
            print("âŒ Kinesis clientê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return

        try:
            # put_records ìš”ì²­ ì¤€ë¹„
            records = []
            for log_event in self.kinesis_batch_buffer:
                partition_key = str(log_event.get("user_id", "default"))
                data = json.dumps(log_event, ensure_ascii=False).encode('utf-8')

                records.append({
                    'Data': data,
                    'PartitionKey': partition_key
                })

            # Kinesisë¡œ ë°°ì¹˜ ì „ì†¡
            response = self.kinesis_client.put_records(
                StreamName=self.kinesis_stream_name,
                Records=records
            )

            # ê²°ê³¼ í™•ì¸
            failed_count = response.get('FailedRecordCount', 0)
            success_count = len(records) - failed_count

            print(f"âœ… Kinesis ë°°ì¹˜ ì „ì†¡: {success_count}/{len(records)}ê°œ ì„±ê³µ", end="")
            if failed_count > 0:
                print(f" ({failed_count}ê°œ ì‹¤íŒ¨)", end="")
            print()

            # ì‹¤íŒ¨í•œ ë ˆì½”ë“œ ì¬ì‹œë„ (ì„ íƒì )
            if failed_count > 0:
                failed_records = []
                for i, record_response in enumerate(response['Records']):
                    if 'ErrorCode' in record_response:
                        failed_records.append(self.kinesis_batch_buffer[i])

                if failed_records:
                    print(f"âš ï¸  {len(failed_records)}ê°œ ë ˆì½”ë“œ ì¬ì‹œë„ í•„ìš”")
                    # TODO: ì¬ì‹œë„ ë¡œì§ êµ¬í˜„ (ì˜µì…˜)

            # ë²„í¼ ì´ˆê¸°í™”
            self.kinesis_batch_buffer.clear()
            self.last_batch_send_time = time.time()

        except ClientError as e:
            print(f"âŒ Kinesis ë°°ì¹˜ ì „ì†¡ ì‹¤íŒ¨: {e}")
            # ë²„í¼ ìœ ì§€ (ì¬ì‹œë„ ê°€ëŠ¥)
        except Exception as e:
            print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            # ë²„í¼ ì´ˆê¸°í™” (ë³µêµ¬ ë¶ˆê°€ëŠ¥í•œ ì˜¤ë¥˜)
            self.kinesis_batch_buffer.clear()
            self.last_batch_send_time = time.time()


    def close(self) -> None:
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ë° ë§ˆì§€ë§‰ ë²„í¼ flush"""
        # Kinesis ë°°ì¹˜ ë²„í¼ flush (streaming-batch ëª¨ë“œ)
        if self.mode == "streaming-batch" and self.kinesis_batch_buffer:
            print(f"ğŸ”„ ë§ˆì§€ë§‰ Kinesis ë°°ì¹˜ ì „ì†¡ ì¤‘... ({len(self.kinesis_batch_buffer)}ê°œ)")
            self._flush_kinesis_batch()

        # í˜„ì¬ ì‹œê°„ëŒ€ ë²„í¼ flush
        if self.current_hour_key is not None and self.current_hour_buffer:
            self._flush_buffer_to_json(self.current_hour_key, self.current_hour_buffer)

        # ë‹¤ìŒ ì‹œê°„ëŒ€ ë²„í¼ flush
        if self.next_hour_key is not None and self.next_hour_buffer:
            self._flush_buffer_to_json(self.next_hour_key, self.next_hour_buffer)

        print("âœ… LogSink ì¢…ë£Œ")
